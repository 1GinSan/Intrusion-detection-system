# -*- coding: utf-8 -*-
"""ML Project book.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17KTpxwVn5B7_h-yTqN2NeA2XQw7IM7tm
"""

import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt

"""Adding the CICIDS2017 data set to the notebook from my drive

and concantenating all csv files together
"""

from google.colab import drive
drive.mount('/content/drive')
!ls "/content/drive/My Drive/CICIDS2017"

dataset_path = "/content/drive/My Drive/CICIDS2017"
all_files = os.listdir(dataset_path)

df_list = []
for file in all_files:
    if file.endswith('.csv'):
        file_path = os.path.join(dataset_path, file)
        df = pd.read_csv(file_path)
        df_list.append(df)

full_dataset = pd.concat(df_list, ignore_index=True)

"""Visualizing the data using Matplotlib and numpy

"""

print("Dataset Shape:", full_dataset.shape)
print("Data Types:\n", full_dataset.dtypes)

df = df.drop_duplicates()#dropping duplicate columns

print("First 5 rows of the dataset:")
print(full_dataset.head())
print("\nLast 5 rows of the dataset:")
print(full_dataset.tail())
print("Summary Statistics:")
print(full_dataset.describe())

for column in full_dataset.columns:
    if full_dataset[column].dtype == 'object':
        print(f"Unique values in {column}: {full_dataset[column].nunique()}")
        print(f"Value counts:\n{full_dataset[column].value_counts()}\n")

print("Missing Values in Each Column:")
print(full_dataset.isnull().sum())

"""IMPLEMENTING RANDOM TRESS"""

print(full_dataset.columns)

"""plotting some aspects"""

plt.hist(full_dataset[' Flow Duration'], bins=50, color='blue', edgecolor='black')
plt.title('Flow Duration Distribution')
plt.xlabel('Flow Duration')
plt.ylabel('Frequency')
plt.show()

# Filter out rows where the 'Label' column is 'BENIGN'
filtered_dataset = full_dataset[full_dataset[' Label'] != 'BENIGN']

# Now plot the histogram of 'Flow Duration' for the filtered dataset
plt.hist(filtered_dataset[' Flow Duration'], bins=50, color='blue', edgecolor='black')
plt.title('Flow Duration Distribution for Non-BENIGN Attacks')
plt.xlabel('Flow Duration')
plt.ylabel('Frequency')
plt.show()

# Filter out the 'BENIGN' category
non_benign_data = full_dataset[full_dataset[' Label'] != 'BENIGN']

# Get unique attack types
attack_types = non_benign_data[' Label'].unique()

# Plot a histogram for each attack type
for attack in attack_types:
    subset = non_benign_data[non_benign_data[' Label'] == attack]
    plt.hist(subset[' Flow Duration'], bins=50, label=attack, alpha=0.5, edgecolor='black')

plt.title('Flow Duration Distribution by Attack Type')
plt.xlabel('Flow Duration')
plt.ylabel('Frequency')
plt.legend(title='Attack Type')
plt.show()

from sklearn.preprocessing import StandardScaler

# Initialize the StandardScaler
scaler = StandardScaler()

# Assuming 'full_dataset' is your DataFrame and 'Flow Duration' is the column you want to standardize

# Filter out the rows with 'BENIGN'
filtered_data = full_dataset[full_dataset[' Label'] != 'BENIGN']

# Fit the scaler on the 'Flow Duration' data and transform it
filtered_data[' Standardized Flow Duration'] = scaler.fit_transform(filtered_data[[' Flow Duration']])

# Now, you can use 'Standardized Flow Duration' for your histogram plots
# Below is your updated code with standardization applied to 'Flow Duration'

import matplotlib.pyplot as plt

# Get unique attack types
attack_types = filtered_data[' Label'].unique()

# Plot a histogram for each attack type
for attack in attack_types:
    subset = filtered_data[filtered_data[' Label'] == attack]
    plt.hist(subset[' Standardized Flow Duration'], bins=50, label=attack, alpha=0.5, edgecolor='black')

plt.title('Standardized Flow Duration Distribution by Attack Type')
plt.xlabel('Standardized Flow Duration')
plt.ylabel('Frequency')
plt.legend(title='Attack Type')
plt.show()

plt.scatter(full_dataset[' Total Fwd Packets'], full_dataset[' Total Backward Packets'], alpha=0.5)
plt.title('Total Fwd Packets vs Total Backward Packets')
plt.xlabel('Total Fwd Packets')
plt.ylabel('Total Backward Packets')
plt.show()

attack_counts = full_dataset[' Label'].value_counts()
plt.bar(attack_counts.index, attack_counts.values)
plt.title('Frequency of Different Types of Network Attacks')
plt.xlabel('Attack Type')
plt.ylabel('Frequency')
plt.xticks(rotation=90)
plt.show()

attack_counts = full_dataset[' Label'].value_counts()

# Remove the 'BENIGN' category from the counts
attack_counts = attack_counts[attack_counts.index != 'BENIGN']

# Now plot the bar graph without 'BENIGN'
plt.bar(attack_counts.index, attack_counts.values)
plt.title('Frequency of Different Types of Network Attacks')
plt.xlabel('Attack Type')
plt.ylabel('Frequency')
plt.xticks(rotation=90)
plt.show()

"""performing PCA analysis"""

# Replace 'inf' and '-inf' with 'NaN'
full_dataset = full_dataset.replace([np.inf, -np.inf], np.nan)
full_dataset = full_dataset.dropna()

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder

# Identify non-numeric columns
non_numeric_columns = full_dataset.select_dtypes(include=['object']).columns

# Apply Label Encoding
for col in non_numeric_columns:
    full_dataset[col] = LabelEncoder().fit_transform(full_dataset[col])

X_scaled = StandardScaler().fit_transform(full_dataset)

pca = PCA()
X_pca = pca.fit_transform(X_scaled)

# Calculate explained variance
explained_variance_ratio = pca.explained_variance_ratio_
cumulative_variance = np.cumsum(explained_variance_ratio)

# Number of components for 96% variance
num_components_96_variance = np.argmax(cumulative_variance >= 0.96) + 1

print("Explained Variance Ratio by Each Component:")
print(pca.explained_variance_ratio_)

cumulative_variance = np.cumsum(pca.explained_variance_ratio_)
print("Cumulative Variance Explained by Components:")
print(cumulative_variance)

num_components_96_variance = np.argmax(cumulative_variance >= 0.96) + 1
print(f"Number of components explaining at least 96% variance: {num_components_96_variance}")

import matplotlib.pyplot as plt

# Plotting the explained variance ratio
plt.figure(figsize=(10, 6))
plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, alpha=0.5, align='center', label='Individual explained variance')
plt.step(range(1, len(cumulative_variance) + 1), cumulative_variance, where='mid', label='Cumulative explained variance')
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal component index')
plt.legend(loc='best')
plt.tight_layout()
plt.show()

"""DESCION TREE ANALYSIS"""



from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score

# Standardize features
scaler = StandardScaler()
X = scaler.fit_transform(full_dataset.drop(' Label', axis=1))
y = full_dataset[' Label']


# Splitting the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Training the Random Forest model
model = RandomForestClassifier(n_estimators=8, max_depth=4)
model.fit(X_train, y_train)

# Making predictions
predictions = model.predict(X_test)

scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')

# Evaluating the model
print(classification_report(y_test, predictions))
print(confusion_matrix(y_test, predictions))

print("Accuracy scores for each fold:", scores)
print("Average cross-validation score:", scores.mean())
print("Standard deviation of cross-validation score:", scores.std())

"""RANDOM FOREST REGRESSION

using flow duration column unusually long or short flow durations may mean some malicious activity.
"""

from sklearn.model_selection import train_test_split

# Assume 'X' are your features and 'y' is your continuous target variable
X = full_dataset.drop(' Label', axis=1)  # Drop the label or any non-numeric columns
y = full_dataset[' Flow Duration']  # Example target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

from sklearn.ensemble import RandomForestRegressor

# Initialize the Random Forest Regressor
regressor = RandomForestRegressor(n_estimators=10, max_depth=5)

# Train the model
regressor.fit(X_train, y_train)

from sklearn.metrics import mean_squared_error, r2_score

# Making predictions
predictions = regressor.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

# Initialize your model
model = RandomForestRegressor(n_estimators=8, max_depth=5)

# Choose the number of folds
num_folds = 4

# Select a scoring metric
scoring_metric = 'neg_mean_squared_error'

# Perform cross-validation
scores = cross_val_score(model, X, y, cv=num_folds, scoring=scoring_metric)

# The scores are returned as negative values by convention.
# Taking the absolute value or negation gives you the actual MSE values.
mse_scores = -scores

# Calculate average MSE and standard deviation across folds
avg_mse = np.mean(mse_scores)
std_mse = np.std(mse_scores)

print(f"Average MSE: {avg_mse}")
print(f"Standard Deviation of MSE: {std_mse}")

"""MLP classifier for the dataset"""

from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
import numpy as np

# Assuming df is your DataFrame

# Preprocessing
X = full_dataset.drop(' Label', axis=1)
y = full_dataset[' Label']

# Handle inf/-inf
X.replace([np.inf, -np.inf], np.nan, inplace=True)
X.fillna(X.mean(), inplace=True)

# Apply StandardScaler
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Encode target variable
encoder = LabelEncoder()
y = encoder.fit_transform(y)

# Splitting the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# MLP Classifier
mlp = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=50, activation='relu', solver='adam')
mlp.fit(X_train, y_train)

# Making predictions and evaluating the model
predictions = mlp.predict(X_test)
print(classification_report(y_test, predictions))
print("Accuracy:", accuracy_score(y_test, predictions))